{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Et tu, Rhody?  A recent editorial in the Provi...</td>\n",
       "      <td>727600136.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A recent post in The Farmington Mirror  our t...</td>\n",
       "      <td>731714618.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Donald Trump, as he often does while...</td>\n",
       "      <td>731714635.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February is Black History Month, and nothing l...</td>\n",
       "      <td>728627182.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The snow was so heavy, whipped up by gusting w...</td>\n",
       "      <td>728627443.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0            1  \\\n",
       "0  Et tu, Rhody?  A recent editorial in the Provi...  727600136.0   \n",
       "1  A recent post in The Farmington Mirror  our t...  731714618.0   \n",
       "2  President Donald Trump, as he often does while...  731714635.0   \n",
       "3  February is Black History Month, and nothing l...  728627182.0   \n",
       "4  The snow was so heavy, whipped up by gusting w...  728627443.0   \n",
       "\n",
       "                2  \n",
       "0  non-propaganda  \n",
       "1  non-propaganda  \n",
       "2  non-propaganda  \n",
       "3  non-propaganda  \n",
       "4  non-propaganda  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding = \"ISO-8859-1\"\n",
    "\n",
    "data = pd.read_csv('Task1_News_Text.csv',encoding = \"ISO-8859-1\",header = None)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['news_text','id','flag']\n",
    "data.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_text</th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Et tu, Rhody?  A recent editorial in the Provi...</td>\n",
       "      <td>727600136.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A recent post in The Farmington Mirror  our t...</td>\n",
       "      <td>731714618.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Donald Trump, as he often does while...</td>\n",
       "      <td>731714635.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February is Black History Month, and nothing l...</td>\n",
       "      <td>728627182.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The snow was so heavy, whipped up by gusting w...</td>\n",
       "      <td>728627443.0</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           news_text           id  \\\n",
       "0  Et tu, Rhody?  A recent editorial in the Provi...  727600136.0   \n",
       "1  A recent post in The Farmington Mirror  our t...  731714618.0   \n",
       "2  President Donald Trump, as he often does while...  731714635.0   \n",
       "3  February is Black History Month, and nothing l...  728627182.0   \n",
       "4  The snow was so heavy, whipped up by gusting w...  728627443.0   \n",
       "\n",
       "             flag  \n",
       "0  non-propaganda  \n",
       "1  non-propaganda  \n",
       "2  non-propaganda  \n",
       "3  non-propaganda  \n",
       "4  non-propaganda  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = data['flag']\n",
    "\n",
    "x = data['news_text']\n",
    "\n",
    "#data1 = data.drop(['flag'],axis = 1)\n",
    "#x = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Et tu, Rhody?  A recent editorial in the Provi...\n",
       "1    A recent post in The Farmington Mirror  our t...\n",
       "2    President Donald Trump, as he often does while...\n",
       "3    February is Black History Month, and nothing l...\n",
       "4    The snow was so heavy, whipped up by gusting w...\n",
       "Name: news_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # for splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25, random_state = 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and count the words and form the term frequency matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'et': 69, 'tu': 201, 'rhody': 172, 'recent': 165, 'editorial': 59, 'providence': 157, 'journal': 108, 'cataloged': 27, 'wrong': 219, 'connecticut': 38, 'ended': 64, 'suggestion': 189, 'gov': 87, 'gina': 84, 'raimondo': 159, 'jobs': 106, 'come': 33, 'rhode': 171, 'island': 103, 'certainly': 29, 'risky': 173, 'nutmeg': 139, 'state': 182, 'beg': 15, 'pardon': 142, 'world': 218, 'famous': 74, 'pension': 143, 'problems': 153, 'persistent': 146, 'economic': 57, 'issues': 105, 'reported': 168, 'just': 109, 'weeks': 210, 'ago': 10, 'significant': 176, 'ways': 209, 'reflect': 166, 'enjoys': 66, 'legacy': 117, 'corruption': 40, 'match': 129, 'projo': 156, 'won': 213, 'pulitzer': 158, 'prize': 151, '1994': 3, 'uncovering': 203, 'widespread': 211, 'court': 42, 'exactly': 70, 'gained': 83, 'moving': 134, 'like': 119, 'income': 98, 'tax': 193, 'estate': 68, 'comparable': 35, 'rates': 161, 'forbes': 82, 'magazine': 127, 'listed': 122, 'states': 183, 'die': 51, 'list': 121, 'interdependence': 101, 'limited': 120, 'exception': 72, 'interstate': 102, 'economy': 58, 'created': 43, 'electric': 62, 'boat': 21, 'groton': 90, 'border': 23, 'wars': 206, 'little': 123, 'bloodshed': 18, 'jokes': 107, 'size': 178, 'maybe': 131, 'honest': 96, 'doesn': 54, 'really': 162, 'lot': 126, 'going': 86, 'department': 48, 'competition': 36, 'fine': 79, 'suffers': 188, 'does': 53, 'new': 138, 'england': 65, 'matter': 130, 'losing': 124, 'residents': 170, 'troubling': 199, 'rate': 160, 'outmigration': 141, 'problem': 152, '2015': 4, '2016': 5, 'ocean': 140, 'experienced': 73, 'net': 137, 'loss': 125, '000': 0, 'filers': 78, 'took': 197, '182': 2, 'million': 132, 'adjusted': 8, 'gross': 89, 'destination': 49, 'people': 145, 'fled': 80, 'massachusetts': 128, 'florida': 81, 'wait': 204, 'moved': 133, 'course': 41, 'population': 149, '3½': 7, 'times': 196, 'big': 17, '175': 1, 'left': 116, 'represent': 169, 'far': 75, 'larger': 113, 'portion': 150, '220': 6, 'concerned': 37, 'neighbor': 136, 'don': 55, 'want': 205, 'poach': 147, 'islanders': 104, 'celebrate': 28, 'growth': 92, 'burgeoning': 24, 'workforce': 217, 'supports': 191, 'cheer': 31, 'cvs': 45, 'buying': 26, 'aetna': 9, 'keeping': 110, 'hartford': 93, 'try': 200, 'woo': 214, 'woonsocket': 215, 'booming': 22, 'especially': 67, 'insurance': 100, 'defense': 47, 'industries': 99, 'helps': 95, 'headquartered': 94, 'emphasize': 63, 'grows': 91, 'decade': 46, 'effect': 60, 'profound': 154, 'board': 20, 'pointed': 148, 'thriving': 195, 'supplier': 190, 'chains': 30, 'develop': 50, 'feeder': 76, 'businesses': 25, 'bloom': 19, 'reasons': 164, 'stain': 181, 'bankruptcy': 13, 'spread': 180, 'suburbs': 187, 'wasteland': 207, 'effects': 61, 'felt': 77, 'way': 208, 'muck': 135, 'better': 16, 'work': 216, 'yes': 220, 'learn': 115, 'similar': 177, 'threatened': 194, 'swamp': 192, 'key': 111, 'differences': 52, 'pensions': 144, 'contractual': 39, 'set': 175, 'statute': 184, 'tough': 198, 'choices': 32, 'anticipated': 11, 'legal': 118, 'battle': 14, 'solve': 179, 'leaders': 114, 'stomach': 185, 'type': 202, 'strategy': 186, 'common': 34, 'including': 97, 'language': 112, 'drive': 56, 'rotary': 174, 'grinder': 88, 'cumbie': 44, 'example': 71, 'glad': 85, 'progress': 155, 'reason': 163, 'regional': 167, 'approach': 12, 'wiser': 212}\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 21)\t3\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t2\n",
      "  (0, 24)\t1\n",
      "  :\t:\n",
      "  (0, 196)\t1\n",
      "  (0, 197)\t1\n",
      "  (0, 198)\t1\n",
      "  (0, 199)\t1\n",
      "  (0, 200)\t2\n",
      "  (0, 201)\t1\n",
      "  (0, 202)\t1\n",
      "  (0, 203)\t1\n",
      "  (0, 204)\t1\n",
      "  (0, 205)\t2\n",
      "  (0, 206)\t1\n",
      "  (0, 207)\t1\n",
      "  (0, 208)\t1\n",
      "  (0, 209)\t1\n",
      "  (0, 210)\t1\n",
      "  (0, 211)\t1\n",
      "  (0, 212)\t1\n",
      "  (0, 213)\t1\n",
      "  (0, 214)\t1\n",
      "  (0, 215)\t1\n",
      "  (0, 216)\t1\n",
      "  (0, 217)\t1\n",
      "  (0, 218)\t1\n",
      "  (0, 219)\t1\n",
      "  (0, 220)\t1\n"
     ]
    }
   ],
   "source": [
    "cv = count_vectorizer.fit([x_train[0]])\n",
    "print(cv.vocabulary_)\n",
    "cv_trans = count_vectorizer.transform([x_train[0]])\n",
    "print(cv_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Et tu, Rhody?  A recent editorial in the Providence Journal cataloged everything it could find wrong with Connecticut and ended with this suggestion: \\x93Gov. Gina Raimondo should see if at least some of those jobs could come to Rhode Island. It is certainly less risky than the Nutmeg State.\\x94  We beg your pardon.  The state with world-famous pension problems and persistent economic issues of its own is \\x93less risky\\x94?  The Journal itself reported just a few weeks ago on Rhode Island\\x92s own significant economic problems, which in many ways reflect Connecticut\\x92s.  Rhode Island enjoys a legacy of corruption that not even Connecticut can match. The ProJo won a Pulitzer Prize in 1994 for uncovering widespread corruption within its own court system.  What, exactly, is to be gained from moving to Rhode Island?  Like Connecticut, Rhode Island has an income tax and an estate tax with comparable rates. (Forbes magazine listed it as one of the states \\x93Where Not To Die.\\x94 Connecticut made the list, too.)  Connecticut and Rhode Island\\x92s interdependence has been limited, with the exception of the interstate economy created by Electric Boat in Groton. There have been no border wars and very little bloodshed. A few jokes about Rhode Island\\x92s size, maybe, but if we\\x92re being honest, Connecticut doesn\\x92t really have a lot going on in that department either.  A little interstate competition is fine, but if Connecticut suffers, so does Rhode Island \\x97 and all of New England, for that matter.  Connecticut is losing residents at a troubling rate, but Rhode Island has an outmigration problem of its own. From 2015 to 2016, the Ocean State experienced a net loss of about 2,000 tax filers, who took with them more than $182 million in adjusted gross income. The top destination states for people who fled Rhode Island were Massachusetts, Florida and \\x97 wait for it \\x97 Connecticut.  Connecticut residents moved to Rhode Island as well, of course. But Connecticut\\x92s population is 3½ times as big as Rhode Island\\x92s. So the 1,175 tax filers who left Rhode Island for Connecticut represent a far larger portion of the Ocean State than the 1,220 who moved from Connecticut to Rhode Island. If any state should be concerned about losing residents to its neighbor, it\\x92s Rhode Island.  But we don\\x92t want to poach Rhode Islanders. We\\x92d rather celebrate Electric Boat\\x92s growth and the burgeoning workforce that supports both states. We\\x92d rather cheer CVS for buying Aetna and keeping it in Hartford than try to woo CVS from Woonsocket.  A booming Connecticut, especially in the insurance and defense industries, only helps Rhode Island.  As Electric Boat \\x97 headquartered in Connecticut, might we emphasize \\x97 grows over the next decade, the effect on Little Rhody will be profound, as the ProJo\\x92s editorial board pointed out. A thriving border economy helps both states as supplier chains develop and as feeder businesses bloom.  But for the same reasons that the stain of a Hartford bankruptcy would spread to the suburbs, if Connecticut becomes an economic wasteland, the effects would be felt across New England.  If Rhode Island and Connecticut want to find a way out of the muck, far better for them to work together.  Yes, Connecticut can learn from Rhode Island. Connecticut\\x92s pension problems are similar to those that threatened to swamp Rhode Island, but there are key differences, especially in that Connecticut\\x92s pensions are contractual, where in Rhode Island, they were set by state statute.  Rhode Island made some tough choices and anticipated a legal battle to solve its problems. Connecticut leaders might have to find the stomach for the same type of strategy.  Connecticut and Rhode Island have a lot in common, including language. We both drive around the rotary to get a grinder at Cumbie\\x92s, for example. And we are glad that Rhode Island has made progress on its pension issues.  But that\\x92s no reason to try to poach a few residents. A regional approach would be much wiser.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_trans.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-158349504e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcount_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcount_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[0;32m    120\u001b[0m                              \"unicode string.\")\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "count_vectorizer.fit(x_train)\n",
    "count_train = count_vectorizer.transform(x_train)\n",
    "count_test = count_vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-450e53b40e61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB()\n",
    "clf.fit(count_train,y_train)\n",
    "pred = clf.predict(count_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
